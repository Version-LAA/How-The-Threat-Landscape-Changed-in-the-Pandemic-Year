{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How The Threat Landscape Changed in the Pandemic Year \n",
    "\n",
    "The purpose of this analysis is to analyze malicious domains submitted to url.abuse[.]ch for the year range of 2019 to 2020. The URL Haus project is an amazing resource used by security practicioners of all kinds to help share and provide insight into malicious urls discovered. The URLhaus project is created and managed by abuse[.]ch, a non profit security reasearcher that manages several additional projects to provide situational awareness and information to aid in internet security against malware.\n",
    "\n",
    "**The goal of this analysis is to answer the following:**\n",
    "\n",
    "- What type of malware is more prominant in the year of the pandemic vs the previous year\n",
    "- Which tld is most seen this year related to malicious threats\n",
    "- Based on analysis are there any specifc hunts organization can perform to identify traffic going to risky domains.\n",
    "- Based on analysis are there any detections organizations can put in place to \n",
    "\n",
    "**Analysis Breakdown**\n",
    "- Data Exploration \n",
    "- Data Cleaning\n",
    "- Analysis \n",
    "- Reporting and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['################################################################'], ['# abuse.ch URLhaus Database Dump (CSV)                         #'], ['# Last updated: 2020-12-29 15:44:07 (UTC)                      #'], ['#                                                              #'], ['# Terms Of Use: https://urlhaus.abuse.ch/api/                  #'], ['# For questions please contact urlhaus [at] abuse.ch           #'], ['################################################################'], ['#'], ['# id', 'dateadded', 'url', 'url_status', 'threat', 'tags', 'urlhaus_link', 'reporter'], ['944671', '2020-12-29 15:44:07', 'http://gbimkd.org/wp-includes/mzYzedwYUHNvfwTTy47Ey0o5tKUyazH0oXIs/', 'online', 'malware_download', 'doc,emotet,epoch2', 'https://urlhaus.abuse.ch/url/944671/', 'Cryptolaemus1']]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from csv import reader\n",
    "\n",
    "#Data Exploration in prep for data cleaning. Converting items in list to quickly asses what the data looks like.\n",
    "\n",
    "\n",
    "of = open(\"csv.txt\")\n",
    "rf = reader(of)\n",
    "data = list(rf)\n",
    "\n",
    "print(data[:10])\n",
    "\n",
    "\n",
    "# Data preview of first 10 rows show some header data prior to columns. Will need to skip those rows prior to cleaning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 931755 entries, 0 to 931754\n",
      "Data columns (total 8 columns):\n",
      " #   Column        Non-Null Count   Dtype \n",
      "---  ------        --------------   ----- \n",
      " 0   # id          931755 non-null  int64 \n",
      " 1   dateadded     931755 non-null  object\n",
      " 2   url           931755 non-null  object\n",
      " 3   url_status    931755 non-null  object\n",
      " 4   threat        931698 non-null  object\n",
      " 5   tags          931755 non-null  object\n",
      " 6   urlhaus_link  931755 non-null  object\n",
      " 7   reporter      931755 non-null  object\n",
      "dtypes: int64(1), object(7)\n",
      "memory usage: 56.9+ MB\n",
      "None \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Creating a dataframe , but will be skipping first 8 rows of header data.\n",
    "\n",
    "urls = pd.read_csv(\"csv.txt\",skiprows=8)\n",
    "\n",
    "columns= urls.columns\n",
    "\n",
    "print(urls.info(),\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration and Data Cleaning \n",
    "\n",
    "- Dataframe created successfully, identifying over 900,000 entries. \n",
    "- Datacleaning steps:\n",
    " 1. Clean up columns to make them easier to work with\n",
    " 2. Create a new column for year based on dateadded column\n",
    " 3. Create a new column for month based on date added column\n",
    " 4. Identify null values\n",
    " 5. Create a new column for domain bsed or url\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old columns \n",
      " Index(['# id', 'dateadded', 'url', 'url_status', 'threat', 'tags',\n",
      "       'urlhaus_link', 'reporter'],\n",
      "      dtype='object') \n",
      "\n",
      "new columns \n",
      " Index(['id', 'date_added', 'url', 'url_status', 'threat', 'tags',\n",
      "       'urlhaus_link', 'reporter'],\n",
      "      dtype='object') \n",
      "\n",
      "data preview: \n",
      "        id           date_added  \\\n",
      "0  944671  2020-12-29 15:44:07   \n",
      "1  944670  2020-12-29 15:44:05   \n",
      "\n",
      "                                                 url url_status  \\\n",
      "0  http://gbimkd.org/wp-includes/mzYzedwYUHNvfwTT...     online   \n",
      "1                       http://116.124.219.2:55737/i     online   \n",
      "\n",
      "             threat               tags                          urlhaus_link  \\\n",
      "0  malware_download  doc,emotet,epoch2  https://urlhaus.abuse.ch/url/944671/   \n",
      "1  malware_download     32-bit,arm,elf  https://urlhaus.abuse.ch/url/944670/   \n",
      "\n",
      "        reporter  \n",
      "0  Cryptolaemus1  \n",
      "1       geenensp  \n"
     ]
    }
   ],
   "source": [
    "#loop through column headers to make naming convention more consistent\n",
    "\n",
    "columns = urls.columns\n",
    "\n",
    "print(\"old columns\",\"\\n\", columns,\"\\n\")\n",
    "\n",
    "new_columns = []\n",
    "\n",
    "for c in columns:\n",
    "    new = c\n",
    "    if c == \"# id\":\n",
    "        new = \"id\"\n",
    "        new_columns.append(new)\n",
    "    elif c ==\"dateadded\":\n",
    "        new = \"date_added\"\n",
    "        new_columns.append(new)\n",
    "        \n",
    "    else:\n",
    "        new_columns.append(new)\n",
    "        \n",
    "urls.columns = new_columns\n",
    "\n",
    "\n",
    "        \n",
    "print(\"new columns\", \"\\n\",urls.columns,\"\\n\")\n",
    "\n",
    "\n",
    "print(\"data preview: \\n\",urls.head(2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing date_added column and creating seperate columns for year and month\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime \n",
    "\n",
    "urls[\"date_added\"] = pd.to_datetime(urls[\"date_added\"])\n",
    "\n",
    "urls[\"year\"] = urls[\"date_added\"].dt.year\n",
    "urls[\"month\"] = urls[\"date_added\"].dt.strftime(\"%b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count     931755\n",
      "unique        12\n",
      "top          Sep\n",
      "freq      202906\n",
      "Name: month, dtype: object\n",
      "count    931755.000000\n",
      "mean       2019.608268\n",
      "std           0.663945\n",
      "min        2018.000000\n",
      "25%        2019.000000\n",
      "50%        2020.000000\n",
      "75%        2020.000000\n",
      "max        2020.000000\n",
      "Name: year, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(urls[\"month\"].describe())\n",
    "\n",
    "print(urls[\"year\"].describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing url column to extract domain\n",
    "\n",
    "- Data contained in URL column is a mixture of hardcoded IP's and fqdn's\n",
    "- Will create a new column named domain_request:\n",
    " 1. For rows where the URL is an IP address, I will indicate \"IP\" as domain_request\n",
    " 2. Fore rows where the URL is a fqdn, I will extract only the tld and append in the column.\n",
    "\n",
    "- I will use the following data cleaning workflow process\n",
    " 1. Explore the data in the column\n",
    " 2. Identify patterns and special cases\n",
    " 3. Remove non applicable characters\n",
    " 4. Perform any data type conversions necessary\n",
    " 5. Rename column or create new column if required.\n",
    " \n",
    "I've previewed the strings below and split them based on the forward slash delimeter as that is is a consisten pattern seen in all url request. i.e. http[s]://[hostname/ip]/[path]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     [http:, , gbimkd.org, wp-includes, mzYzedwYUHN...\n",
      "1                     [http:, , 116.124.219.2:55737, i]\n",
      "2     [http:, , www.ticketshd.com, wp-content, FUfYN...\n",
      "3     [http:, , thefiercevagabond.com, cgi-bin, Ebob...\n",
      "4     [http:, , 175.10.51.6:57578, Mozi.a;chmod+777+...\n",
      "5     [https:, , www.hintup.com.br, wp-content, FE9Q...\n",
      "6     [http:, , ondigital.one, wp-admin, up9pp9KLyef...\n",
      "7     [https:, , hdgarden.vn, wp-includes, aZBWciJOr...\n",
      "8                     [http:, , 115.56.159.28:57022, i]\n",
      "9     [https:, , www.lixko.com, wp-includes, LEq9VJd, ]\n",
      "10    [https:, , surfboarddigital.com, carol-stream-...\n",
      "11             [https:, , srishtiherbs.com, jms, bq8, ]\n",
      "12         [https:, , unikaryapools.com, wp, ysFiRq1, ]\n",
      "13                  [http:, , 207.254.247.210:49250, i]\n",
      "14                   [http:, , 120.57.103.125:55379, i]\n",
      "15        [https:, , technicalashish.in, wp-admin, M, ]\n",
      "16    [http:, , thespaceastronauts.com, wp-content, ...\n",
      "17        [http:, , sanghuangvip.com, wp-admin, 7ezn, ]\n",
      "18               [http:, , 117.242.211.7:40745, bin.sh]\n",
      "19    [http:, , nasabatam.bbtbatam.com, wp-admin, Qw...\n",
      "20      [https:, , ilmeteo.dev.keyformat.it, tpl, GB, ]\n",
      "21    [https:, , www.scooterinsurance.co.uk, wp-incl...\n",
      "22    [http:, , 4k-iptv.eu, joinery-companies-hz4lm,...\n",
      "23    [http:, , 4lifedashka.com, wp-admin, HYc85QxIr...\n",
      "24               [http:, , 116.124.219.2:55737, bin.sh]\n",
      "25    [http:, , g2sportstech.com, wp-content, 4RELhj...\n",
      "26    [http:, , www.casadeculturazazu.com.br, wp-con...\n",
      "27                    [http:, , 222.141.22.29:43435, i]\n",
      "28              [http:, , 103.217.123.86:46620, Mozi.m]\n",
      "29                [http:, , 103.41.25.51:43784, Mozi.m]\n",
      "Name: url, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(urls[\"url\"].str.split(\"/\").head(30))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the preview of data above, the hostname/ip is located at index 2.\n",
    "\n",
    "- I will exstract the domain/ip and place in a newly created column named host"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0               gbimkd.org\n",
      "1      116.124.219.2:55737\n",
      "2        www.ticketshd.com\n",
      "3    thefiercevagabond.com\n",
      "4        175.10.51.6:57578\n",
      "5        www.hintup.com.br\n",
      "6            ondigital.one\n",
      "7              hdgarden.vn\n",
      "8      115.56.159.28:57022\n",
      "9            www.lixko.com\n",
      "Name: host, dtype: object\n"
     ]
    }
   ],
   "source": [
    "urls[\"host\"]= urls[\"url\"].str.split(\"/\").str[2]\n",
    "\n",
    "print(urls[\"host\"].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some additional parsing will need to be completed to isolate the TLD.In the following section I will create an addition new column named tld. To accomplish this, I will need to do the following:\n",
    "- Perform another split on the coloumn, but this split will be based on the \".\" dellimeter.\n",
    "- I will append the last item in the index to the tld column\n",
    "- Some challenges with the data and observations are\n",
    " 1. some domains have two tld appended i.e. .org.com\n",
    " 2. request to IP addresses also include port value.\n",
    " \n",
    "- I will create a test dataframe with a subset of data. For fields that contain\":\", I will indicate that as an IP, for all others, I will simply take the last domain listed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year                   host  tld\n",
      "0  2020             gbimkd.org  org\n",
      "1  2020    116.124.219.2:55737   ip\n",
      "2  2020      www.ticketshd.com  com\n",
      "3  2020  thefiercevagabond.com  com\n",
      "4  2020      175.10.51.6:57578   ip\n",
      "5  2020      www.hintup.com.br   br\n",
      "6  2020          ondigital.one  one\n",
      "7  2020            hdgarden.vn   vn\n",
      "8  2020    115.56.159.28:57022   ip\n",
      "9  2020          www.lixko.com  com\n"
     ]
    }
   ],
   "source": [
    "testdata= urls[[\"year\",\"host\"]].head(10)\n",
    "\n",
    "#print(testdata)\n",
    "\n",
    "testdata[\"tld\"] = testdata[\"host\"].str.split(\".\").str[-1]\n",
    "\n",
    "#print(testdata)\n",
    "\n",
    "filter = testdata[\"tld\"].str.contains(\":\")\n",
    "\n",
    "\n",
    "\n",
    "testdata.loc[filter,\"tld\"] = \"ip\"\n",
    "\n",
    "print(testdata)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that I've testing code on a subset of data, will apply to the full DB and previiew the data below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    year                    host  tld\n",
      "0   2020              gbimkd.org  org\n",
      "1   2020     116.124.219.2:55737   ip\n",
      "2   2020       www.ticketshd.com  com\n",
      "3   2020   thefiercevagabond.com  com\n",
      "4   2020       175.10.51.6:57578   ip\n",
      "5   2020       www.hintup.com.br   br\n",
      "6   2020           ondigital.one  one\n",
      "7   2020             hdgarden.vn   vn\n",
      "8   2020     115.56.159.28:57022   ip\n",
      "9   2020           www.lixko.com  com\n",
      "10  2020    surfboarddigital.com  com\n",
      "11  2020        srishtiherbs.com  com\n",
      "12  2020       unikaryapools.com  com\n",
      "13  2020   207.254.247.210:49250   ip\n",
      "14  2020    120.57.103.125:55379   ip\n",
      "15  2020      technicalashish.in   in\n",
      "16  2020  thespaceastronauts.com  com\n",
      "17  2020        sanghuangvip.com  com\n",
      "18  2020     117.242.211.7:40745   ip\n",
      "19  2020  nasabatam.bbtbatam.com  com\n"
     ]
    }
   ],
   "source": [
    "urls[\"tld\"] = urls[\"host\"].str.split(\".\").str[-1]\n",
    "\n",
    "filter = urls[\"tld\"].str.contains(\":\")\n",
    "\n",
    "urls.loc[filter,\"tld\"] = \"ip\"\n",
    "\n",
    "print(urls[[\"year\",\"host\",\"tld\"]].head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count     931755\n",
      "unique       843\n",
      "top           ip\n",
      "freq      501060\n",
      "Name: tld, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(urls[\"tld\"].describe())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
